{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Courseware Environment Build Manual\n",
    "<HR>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Requirement of machine targeted for Courseware deployment\n",
    "In order to build courseware, you need at least three machines below.\n",
    "* Ansible : Use to build and deploy Courseware\n",
    "* Hub : Management node of JupyterHub. Become an Access Point for built Courseware environment.\n",
    "* Node : The node on which the Jupyter server runs.\n",
    "\n",
    "But you can increase the _Node_ machine if necessary. (See section 3 for build directory) \n",
    "\n",
    "### Requirement\n",
    "* **OS:** Ubuntu 14.04.x \n",
    "* **Memory:** 4096Mbyte or more. In the case of a _Node_, it needs to be increased by the number of Jupyter Servers to be started.\n",
    "* **Disk:** 50Gbyte or more. In the case of a _Node_, it needs to be increased by the number of Jupyter Servers to be started.\n",
    "* **NIC:** 2 NICs  (For publick network and private network) \n",
    "* **Username:**  Each machines should be have an account with the user name \"ubuntu\".\n",
    "* **SSH keys:**  It should also have the same public ssh key saved at /home/ubuntu/.ssh/authorized_keys and /root/.ssh/authorized_keys.The corresponding private key should be saved in the build directory in a file named **sshkey**.  (See section 3 for _build directory_) <br>\n",
    "* **Please update:** The commands apt-get update and apt-get upgrade should be run on each instance.\n",
    "\n",
    "### Example\n",
    "* See <a href=\"#appendix_3\">Appendix 3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clone jupyter-platform-dev repository\n",
    "Clone repository _jupyter-platform-dev_ of github  onto any machine.<br>\n",
    "### Required packages\n",
    "```\n",
    "ssh-keygen\n",
    "```\n",
    "### Clone\n",
    "```\n",
    "$ cd YOUR_CLONE_DIR\n",
    "$ git clone git@github.com:axsh/jupyter-platform-dev.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create the build directory\n",
    "```\n",
    "$ cd jupyter-platform-dev\n",
    "$ nodecount=2 ./ind-steps/build-jh-environment/toplevel-generic-build.sh-new /some/directory/path/buildname\n",
    "## ( The value for the environment variable nodecount could be 1, 2 or some other reasonable integer. )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Edit configuration files\n",
    "The ```toplevel-generic-build.sh-new``` script creates a folder structure with the following files and contents:\n",
    "```\n",
    "$ head $(find /some/directory/path/buildname -name datadir.conf)\n",
    "==> Node2 machine: /some/directory/path/buildname/jhvmdir-node2/datadir.conf <==\n",
    "VMIP=192.168.999.999  # replace with the private IP used between instances\n",
    "publicip=180.123.999.999 # replace with IP used by this script\n",
    "publicport=22   # if needed, replace with the port used by this script\n",
    "\n",
    "==> Node1 machine: /some/directory/path/buildname/jhvmdir-node1/datadir.conf <==\n",
    "VMIP=192.168.999.999  # replace with the private IP used between instances\n",
    "publicip=180.123.999.999 # replace with IP used by this script\n",
    "publicport=22   # if needed, replace with the port used by this script\n",
    "\n",
    "==> Ansible machine: /some/directory/path/buildname/jhvmdir/datadir.conf  <==\n",
    "VMIP=192.168.999.999  # replace with the private IP used between instances\n",
    "publicip=180.123.999.999 # replace with IP used by this script\n",
    "publicport=22   # if needed, replace with the port used by this script\n",
    "\n",
    "==> Hub machine: /some/directory/path/buildname/jhvmdir-hub/datadir.conf <== \n",
    "VMIP=192.168.999.999  # replace with the private IP used between instances\n",
    "publicip=180.123.999.999 # replace with IP used by this script\n",
    "publicport=22   # if needed, replace with the port used by this script\n",
    "\n",
    "==> /some/directory/path/buildname/datadir.conf <==\n",
    "node_list=\"node1 node2\"\n",
    "```\n",
    "Each jhvmdir*/datadir.conf file should be edited to contain information for one instance. (In this example, there are 4, i.e. two docker swarm instances plus a hub instance, plus an instance for ansible.)\n",
    "\n",
    "The _publicip_ variable value should be replaced by an IP address that can be used to ssh from the machine hosting the build directory to the corresponding instance. The _publicport_ variable value should point to the ssh port, if port forwarding is used to reach the instance.\n",
    "\n",
    "_VMIP_ should be a private IP address visible to all the other instances. Ssh must be possible to port 22 on this address.\n",
    "\n",
    "\n",
    "### Example\n",
    "* See <a href=\"#appendix_3\">Appendix 3</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Install Courseware\n",
    "Once all the instances exist and all the information has been edited into the datadir.conf files, the following will install Courseware system, taking somewhat more than 60 minutes:\n",
    "```\n",
    "$ /path/to/just/a/little/disk/buildname/toplevel-generic-build.sh do\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check build\n",
    "The build can be checked by running:\n",
    "```\n",
    "$ /path/to/just/a/little/disk/buildname/toplevel-generic-build.sh check\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Initialize course\n",
    "$ ./bin/coursectl new COURSE_DIR MAIL_ADDRESS ACCESS_POINT\n",
    "```\n",
    "COURSE_DIR  : directory of the Courseware environmet each course. \n",
    "MAIL_ADDRESS : e-mail address of the course administrator (generally teacher of lecture).\n",
    "ACCESS_POINT: access point of the course.  The FQDN of the Hub machine. \n",
    "```\n",
    "\n",
    "```\n",
    "ex)\n",
    "$ cd YOUR_CLONE_DIR/jupyter-platform-dev\n",
    "$ ./bin/coursectl new /some/directory/path/buildname foo@example.com hub.example.com\n",
    "```\n",
    "\n",
    "After execution, the login password of course administrator is displayed in the following format.\n",
    "```\n",
    "admin password: nQ8nv]E3wz\n",
    "```\n",
    "The course administrator can log in to the course with this email address and this password.<br>\n",
    "You can change this password by _coursectl_ command. See <a href=\"#appendix_1\">Appendix 1</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Access course\n",
    "You can access the built course by the following URL. *ACCESS_POINT* is the FQDN of the Hub machine.\n",
    "\n",
    "https://ACCESS_POINT/login\n",
    "```\n",
    "Email Address: e-mail address of the course administrator\n",
    "Password: Password returned by \"/bin/coursectl new\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<HR>\n",
    "<a name=\"appendix_1\"></a>\n",
    "# Appendix 1 ： Change/Reset password\n",
    "## Change password of the specified local user.\n",
    "``` $ YOUR_CLONE_DIR/bin/coursectl change-password COURSE_DIR USER_EMAIL NEW_PASSWORD```\n",
    "```\n",
    "COURSE_DIR  : directory of the Courseware environmet each course.\n",
    "USER_EMAIL : e-mail address of the local user to change the password.\n",
    "NEW_PASSWORD : new password. \n",
    "```\n",
    "## Rset password of the specified local user.\n",
    "``` $ YOUR_CLONE_DIR/bin/coursectl reset-password COURSE_DIR USER_EMAIL```\n",
    "```\n",
    "COURSE_DIR  : directory of the Courseware environmet each course.\n",
    "USER_EMAIL : e-mail address of the local user to change the password.\n",
    "\n",
    "output : A new password will be displayed.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix 2 ： ssh wrapper scripts\n",
    "If necessary, the ssh wrapper scripts for each instance can be modified directly. Normally this should only be necessary if special ssh parameters or workarounds are required.\n",
    "```\n",
    "$ cd /some/directory/path/buildname\n",
    "$ find -name ssh-shortcut.sh\n",
    "jhvmdir/ssh-shortcut.sh\n",
    "jhvmdir-hub/ssh-shortcut.sh\n",
    "jhvmdir-node3/ssh-shortcut.sh\n",
    "jhvmdir-node2/ssh-shortcut.sh\n",
    "jhvmdir-node1/ssh-shortcut.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"appendix_3\"></a>\n",
    "# Appendix 3 ： Example for KVM set up\n",
    "## Set up  a private bridge\n",
    "```\n",
    "$ sudo brctl addbr jhub-priv0\n",
    "$ sudo ip link set jhub-priv0 up\n",
    "$ sudo bash -c 'echo \"allow jhub-priv0\" >>/etc/qemu-kvm/bridge.conf'\n",
    "```\n",
    "\n",
    "## Sample script for starting the kvm instances\n",
    "This script will start 3 KVMs with one node.\n",
    "```\n",
    "#/bin/bash\n",
    "\n",
    "set -x\n",
    "\n",
    "mkdir kvm-for-ansible\n",
    "cd kvm-for-ansible\n",
    "tar xzvf ~/ubuntu-image-resources/ubuntu-14-instance-build.img-sshkeys-update-upgrade.tar.gz\n",
    "\n",
    "/usr/libexec/qemu-kvm -m 4096 -smp 2 -vnc :10 -drive file=ubuntu-14-instance-build.img,id=vol-tu3y7qj4-drive,if=none,serial=vol-tu3y7qj4,cache=none,aio=native -device virtio-blk-pci,id=vol-tu3y7qj4,drive=vol-tu3y7qj4-drive,bootindex=0,bus=pci.0,addr=0x4 -net nic,vlan=0,macaddr=52:54:00:65:10:dd,model=virtio,addr=10 -net user,net=10.0.2.0/24,vlan=0,hostfwd=tcp::11022-:22,hostfwd=tcp::11043-192.168.44.10:443 -net nic,vlan=1,macaddr=52:54:00:12:10:99 -net bridge,br=jhub-priv0,vlan=1 >kvm.stdout 2>kvm.stderr &\n",
    "cd ..\n",
    "\n",
    "mkdir kvm-for-hub\n",
    "cd kvm-for-hub\n",
    "tar xzvf ~/ubuntu-image-resources/ubuntu-14-instance-build.img-sshkeys-update-upgrade.tar.gz\n",
    "\n",
    "/usr/libexec/qemu-kvm -m 4096 -smp 2 -vnc :11 -drive file=ubuntu-14-instance-build.img,id=vol-tu3y7qj4-drive,if=none,serial=vol-tu3y7qj4,cache=none,aio=native -device virtio-blk-pci,id=vol-tu3y7qj4,drive=vol-tu3y7qj4-drive,bootindex=0,bus=pci.0,addr=0x4 -net nic,vlan=0,macaddr=52:54:00:65:11:dd,model=virtio,addr=10 -net user,net=10.0.2.0/24,vlan=0,hostfwd=tcp::11122-:22,hostfwd=tcp::11143-192.168.44.11:443 -net nic,vlan=1,macaddr=52:54:00:12:11:99 -net bridge,br=jhub-priv0,vlan=1 >kvm.stdout 2>kvm.stderr &\n",
    "cd ..\n",
    "\n",
    "mkdir kvm-for-node\n",
    "cd kvm-for-node\n",
    "tar xzvf ~/ubuntu-image-resources/ubuntu-14-instance-build.img-sshkeys-update-upgrade.tar.gz\n",
    "\n",
    "/usr/libexec/qemu-kvm -m 4096 -smp 2 -vnc :12 -drive file=ubuntu-14-instance-build.img,id=vol-tu3y7qj4-drive,if=none,serial=vol-tu3y7qj4,cache=none,aio=native -device virtio-blk-pci,id=vol-tu3y7qj4,drive=vol-tu3y7qj4-drive,bootindex=0,bus=pci.0,addr=0x4 -net nic,vlan=0,macaddr=52:54:00:65:12:dd,model=virtio,addr=10 -net user,net=10.0.2.0/24,vlan=0,hostfwd=tcp::11222-:22,hostfwd=tcp::11243-192.168.44.12:443 -net nic,vlan=1,macaddr=52:54:00:12:12:99 -net bridge,br=jhub-priv0,vlan=1 >kvm.stdout 2>kvm.stderr &\n",
    "cd ..\n",
    "```\n",
    "\n",
    "## Sample script for KVM instance set up \n",
    "This script will start 3 KVMs to set up an environment with one node.<br>\n",
    "**Notice : ** Now, the system only works if connections are made directly to a 443 port. So if you use KVM instance for Courseware infrastructure, you have to foward from KVM host 443 port to the KVM 443 port.\n",
    "```\n",
    "#/!bin/bash\n",
    "\n",
    "set -x\n",
    "\n",
    "generate_setup_script() {\n",
    "    addr=\"$1\" publicaddr=\"$2\" hostname=\"$3\"\n",
    "cat <<EOF\n",
    "\n",
    "echo 'ubuntu ALL=(ALL) NOPASSWD: ALL' >>/etc/sudoers\n",
    "rm /etc/update-motd.d/*\n",
    "\n",
    "# the next line is necessary or docker pulls do not work reliably\n",
    "# related: https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=625689\n",
    "echo \"prepend domain-name-servers 8.8.8.8;\" | sudo tee -a /etc/dhcp/dhclient.conf\n",
    "\n",
    "sudo apt-get update\n",
    "sudo apt-get -y install git\n",
    "\n",
    "sudo tee -a /etc/network/interfaces <<EOF2\n",
    "\n",
    "auto eth1\n",
    "iface eth1 inet static\n",
    "    address $addr\n",
    "    netmask 255.255.255.0\n",
    "EOF2\n",
    "\n",
    "# sudo ifdown eth1\n",
    "sudo ifup eth1\n",
    "\n",
    "echo \"$hostname\" >/etc/hostname\n",
    "echo $publicaddr \"$hostname\" >>/etc/hosts\n",
    "hostname \"$hostname\"\n",
    "\n",
    "EOF\n",
    "}\n",
    "\n",
    "ssh root@localhost -p 11022 -i ./sshkey <<<\"$(generate_setup_script 192.168.44.10 180.168.44.10 ansible)\"\n",
    "ssh root@localhost -p 11122 -i ./sshkey <<<\"$(generate_setup_script 192.168.44.11 180.168.44.10 hub)\"\n",
    "ssh root@localhost -p 11222 -i ./sshkey <<<\"$(generate_setup_script 192.168.44.12 180.168.44.10 node1)\"\n",
    "```\n",
    "\n",
    "### Example of datadir.conf for the set-up environment by the sample script\n",
    "```\n",
    "$ cat /some/directory/path/buildname/jhvmdir/datadir.conf\n",
    "VMIP=192.168.44.10\n",
    "publicip=180.168.44.10\n",
    "publicport=11022\n",
    "\n",
    "$ cat /some/directory/path/buildname/jhvmdir-hub/datadir.conf\n",
    "VMIP=192.168.44.11\n",
    "publicip=180.168.44.10\n",
    "publicport=11122\n",
    "\n",
    "$ cat /some/directory/path/buildname/jhvmdir-node1/datadir.conf\n",
    "VMIP=192.168.44.12\n",
    "publicip=180.168.44.10\n",
    "publicport=11222\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
